# config.yaml

api:
  model: "deepseek-chat"
  max_tokens: 8192
  temperature: 0
  base_url: "https://api.deepseek.com"

files:
  input: "inputs/distribution_set_final_deepseek.jsonl"
  output:
    base_name: "outputs/transmission_chain"
    base: "outputs/transmission_chain.jsonl"
    discarded: "outputs/transmission_chain_discarded.jsonl"
    excluded_trim: "outputs/transmission_chain_excluded_trim.jsonl"
    excluded_temporal: "outputs/transmission_chain_excluded_temporal.jsonl"
    excluded_remainder: "outputs/transmission_chain_excluded_remainder.jsonl"
  
logging:
  filename: "logs/processing_deepseek.log"
  level: "INFO"
  format: "%(asctime)s - %(levelname)s - %(message)s"

processing:
  id_range:
    min: 2024
    max: 2026
